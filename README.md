# Neurotech@Berkeley Fall 2020 NMEP EEG Group 1 Final Project

**Dataset**: [An EEG dataset recorded during affective music listening](https://openneuro.org/datasets/ds002721/versions/1.0.1)

**Reference Paper**: [Neural and physiological data from participants listening to affective music](https://www.nature.com/articles/s41597-020-0507-6)

# Introduction

Music has been shown to have the capacity to affect emotional and even physiological states. However, the neurological mechanisms through which musical stimuli induces affect are still unknown, with lack of data in the cognitive and emotional states resulting from stimuli. In a recent study by I. Daly, et. al., researchers provide datasets on musical stimuli and its resulting effects on affective states as well as neurological and physical activity.  In conducting experiments using using functional magnetic resonance imaging (fMRI), electroencephalogram (EEG), electrocardiogram (ECG), galvanic skin response (GSR), and respiration rates, the scientists recorded 4 key datasets: ‘Film Clips,’ ‘Brain Computer Music Interface (BCMI),’ ‘BCMI-tempo,’ and ‘Joint EEG-fMRI.’ The film clips dataset investigated effects of short clips of acoustic film music on participants’ emotions and their EEG recordings, providing data on the EEGs and responses of participants to Likert questions on emotional states following acoustic film music. The BCMI dataset was constructed to examine the modification of affective state, identifying the participant’s current state and modifying by playing a sequence of generated music pieces and recording subsequent data through EEG, GSR, and ECG.  The BCMI-tempo dataset was developed to research the connection between motor imagery and EEG, allowing participants to alter tempo of a piece through motor imagery and recording the resulting EEG data. The final joint EEG-fMRI dataset led to two sets of stimuli (synthetic music for targeting specific affective states and classical music for inducing a wide range of states) being used to record the participant’s current felt affective states, and arm and eye movements. 

As the goal of the researchers was to collect and contribute invaluable information on emotion, music and neural and physiological activity, the authors did not analyze or interpret their study. This therefore allows our project to use the data of I. Daly, et. al. to examine the connection between affective cognitive, emotional, and physiological states as dependent on musical stimuli. Specifically for our project, we examine the neurological responses and correlates resulting from different types of music. 

## Article Summary

Our group will be focusing on answering the question: how do neurological responses vary across different types of music? To answer this question we will be using a data set corresponding to the following summarized article.

## Overview
In this article, a group of researchers set out to gather data to advance the scientific understanding of the neurological processes that enable music to produce affective responses in humans. It is well known that music has the ability to induce a wide range of emotions and alter human affective. The focus of this article is at the intersection of neurological activity, reported emotions, and music. The data presented in this article is based on several different experiments that the researchers conducted using functional magnetic resonance imaging (fMRI), electroencephalogram (EEG), electrocardiogram (ECG), galvanic skin response (GSR), and respiration rates as tools to measure neurological activity while participants listened to music. There were a total of 114 participants in the study, ages ranged from 18 to 66, and participants were evenly divided between men and women. The authors did not analyze or interpret the information they collected, rather their goal was to contribute valuable data for other researchers investigating emotion, music, and how they affect neural and physiological activity.

## Procedure

The article presents 4 key data sets that the authors present as the basis for the majority of the research conducted in the project. The data sets are as follows...

1. The ‘Film clips’ dataset, which contains EEG recorded while participants listened to short music clips extracted from films and chosen to induce specific emotional responses.

2. The ‘Brain-Computer Music Interface’ dataset, which contains EEG and other physiological signals recorded during development and evaluation of the Brain-Computer Music Interface (BCMI) system developed in the project. This dataset is divided into three parts: calibration, training, and testing.

3. The ‘BCMI tempo’ dataset, which contains EEG recorded while developing a BCMI for controlling the tempo of music.

4. The ‘Joint EEG-fMRI’ dataset, which contains EEG and fMRI recorded simultaneously from participants while they listened to both synthetic and classical music and reported their current felt affective states on a continuous basis.



**References**: <br />
[1] Daly, I., Nicolaou, N., Williams, D., Hwang, F., Kirke, A., Miranda, E., Nasuto, S.J., “Neural and physiological data from participants listening to affective music”, Scientific Data, 2018.<br />
[2] Daly, I., Malik, A., Hwang, F., Roesch, E., Weaver, J., Kirke, A., Williams, D., Miranda, E. R., Nasuto, S. J., “Neural correlates of emotional responses to music: an EEG study”, Neuroscience Letters, 573: 52-7, 2014; doi: 10.1016/j.neulet.2014.05.003. <br />
[3] Daly, I., Hallowell, J., Hwang, F., Kirke, A., Malik, A., Roesch, E., Weaver, J., Williams, D., Miranda, E., Nasuto, S.J., “Changes in music tempo entrain movement related brain activity”, Proc. IEEE EMBC 2014, pp.4595-8; doi: 10.1109/EMBC.2014.6944647. <br />
[4] Daly, I., Williams, D., Hallowell, J., Hwang, F., Kirke, A., Malik, A., Weaver, J., Miranda, E., Nasuto, S.J., “Music-induced emotions can be predicted from a combination of brain activity and acoustic features”, Brain and Cognition, 101:1-11, 2015b; doi: 10.1016/j.bandc.2015.08.003.

